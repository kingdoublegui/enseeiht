<h1>Régulation </h1>

<h2>Objectifs</h2>

<ul>
<li>gérer le parallélisme à gros grain</li>
<li>paralléliser un algorithme par décomposition en sous-tâches</li>
<li>connaître les services d'exécution de la plateforme Java</li>
</ul>

<h2>Prérequis</h2>

<p>Vous devez savoir parfaitement comment définir une activité (Thread) en Java, 
comment lancer une activité, et comment attendre sa terminaison.</p>

<p><em>* Si ce n'est pas le cas,
(re)voyez et (re)faites le travail demandé à la rubrique « concurrence et cohérence » avant
d'entamer ce TP</em>*</p>

<p>Vous aurez vraisemblablement besoin lors de ce TP d'utiliser les méthodes de classe suivantes 
de la classe <code>Thread</code> :</p>

<ul>
<li><code>static Thread currentThread()</code> qui fournit la référence du thread en cours d'exécution</li>
<li><code>static void sleep(long ms) throws InterruptedException</code> qui suspend le thread 
appelant pour une durée de <code>ms</code> millisecondes</li>
</ul>

<p>Enfin, vous aurez sans doute aussi besoin de deux méthodes de classe de la classe <code>System</code> :
<code>System.nanoTime()</code> et <code>System.currentTimeMillis()</code> qui fournissent une durée écoulée 
(en ns et ms) depuis une date d'origine non spécifiée.  La différence entre les valeurs 
retournées par deux appels successifs permet d'évaluer le temps écoulé entre ces deux appels.</p>

<h2>Préparation : services de régulation des activités en Java</h2>

<p><em>La rapide présentation qui suit peut être complétée par la lecture de la partie 
correspondante du cours sur les processus légers (planches 22-30) pour les notions et sur la 
<a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/package-summary.html">documentation Java en ligne</a> 
pour la syntaxe et les détails techniques.</em></p>

<p>Les classes et notions utilisées jusqu'ici étaient destinées à définir et gérer la concurrence
explicitement, et à un niveau fin : le choix de lancer, d'attendre et de terminer une tâche
appartient entièrement au programmeur. De même, le programmeur a la charge des choix en
termes de gestion de la cohérence (variables <code>volatile</code>, classes atomiques...) et du type 
d'attente (blocs <code>synchronized</code>, verrous, attente active).</p>

<p>La plateforme Java fournit dans ses dernières versions la classe <code>Executor</code>, destinée à
séparer la gestion des activités des aspects purement applicatifs. Le principe est qu'un
objet de la classe <code>Executor</code> (« exécuteur ») fournit un <em>service</em> de gestion et d'ordonnancement 
d'activités, auquel on soumet des <em>tâches</em> à traiter. Une application est donc vue comme
un ensemble de tâches qui sont fournies à l'exécuteur. L'exécuteur gère alors l'exécution 
des tâches qui lui sont soumises de manière indépendante et transparente pour l'application.
L'objectif de ce service est de permettre</p>

<ul>
<li>de simplifier la tâche du programmeur, puisqu'il n'a plus à gérer le démarrage des activités,
ni leur ordonnancement</li>
<li>d'adapter le nombre d'activités exécutées à la charge et au nombre de processeurs 
physiques disponibles</li>
</ul>

<p>Le paquetage <code>java.util.concurrent</code> définit 3 interfaces pour les exécuteurs :</p>

<ul>
<li><code>Executor</code>, qui fournit une méthode <code>execute</code>, permettant de soumettre une tâche <code>Runnable</code>.</li>
<li><code>ExecutorService</code>, qui étend <code>Executor</code>, avec une méthode <code>submit</code>, permettant de
soumettre une tâche <code>Callable</code> et renvoyant un objet <code>Future</code>, lequel permet de récupérer
la valeur de retour de la tâche <code>Callable</code> soumise. Un <code>ExecutorService</code> permet en outre 
de soumettre des ensembles de tâches <code>Callable</code>, et de gérer la terminaison de l'exécuteur.</li>
<li><code>ScheduledExecutorService</code>, qui étend <code>ExecutorService</code> avec des méthodes permettant de 
spécifier l'ordonnancement des tâches soumises.</li>
</ul>

<p>Le paquetage <code>java.util.concurrent</code> fournit différentes implémentations d'exécuteurs. Le
principe commun aux exécuteurs est de distribuer les tâches soumises à un ensemble
d'ouvriers. Chaque ouvrier est un thread cyclique, qui traite une par une les tâches qui
lui sont attribuées.</p>

<p>Les exécuteurs fournis par le paquetage <code>java.util.concurrent</code> sont de deux sortes :</p>

<h3>Pools de threads</h3>

<p>La classe <code>java.util.concurrent.Executors</code> fournit des méthodes permettant de créer des
pools de threads implantant <code>ExecutorService</code> avec un nombre d'ouvriers fixe 
-- méthode <code>newFixedThreadPool</code> --, variable (adaptable) -- méthode <code>newCachedThreadPool</code>) ou 
permettant une régulation par vol de tâches (voir cours) (méthode <code>newWorkStealingPool</code>). 
Une variante implantant <code>ScheduledExecutorService</code> est proposée pour chacune de ces
 méthodes, afin de permettre d'intervenir sur l'ordonnancement des tâches. Enfin, les classes
<code>java.util.concurrent.ThreadPoolExecutor</code> et <code>java.util.concurrent.ScheduledThreadPoolExecutor</code>
 proposent encore davantage d'options sur la paramétrage et la supervision de l'ordonnancement.</p>

<p>Les pools de threads évitent la création de nouveaux threads pour chaque tâche à traiter,
puisque qu'un même ouvrier est réutilisé pour traiter une suite de tâches, ce qui présente
plusieurs avantages :</p>

<ul>
<li>éviter la création de threads apporte un gain (significatif lorsque les tâches sont nombreuses)
en termes de  consommation de ressources mémoire et processeur,</li>
<li>le délai de prise en charge des requêtes est réduit du temps de la création du traitant
de la requête,</li>
<li>enfin, et surtout, le contrôle du nombre d'ouvriers va permettre de réguler et d'adapter
l'exécution en fonction des ressources matérielles disponibles, au lieu d'avoir une exécution
directement dépendante du flux de tâches à traiter. Ainsi, dans le cas d'un flux de tâches
augmentant brutalement (comme dans le cas d'une attaque par déni de service), les performances
se dégraderont progressivement (car le délai de prise en charge augmentera proportionnellement
au nombre de tâches en attente), mais il n'y aura pas d'écroulement dû à un épuisement des
ressources nécessaires.</li>
</ul>

<p>D'une manière générale, </p>

<ul>
<li>Le choix ou l'adaptation du nombre d'ouvriers en fonction du nombre de processeurs
effectivement disponibles et de la charge courante est un élément clé de la
parallélisation avec un pool de threads : trop peu nombreux, les ouvriers ne pourront
exploiter tous les processeurs ; trop nombreux, il mobiliseront des ressources inutilement
et auront un impact négatif sur les performances.</li>
<li>Les pools de threads sont bien adaptés au traitement de problèmes
réguliers, c'est à dire aux problèmes décomposables en sous-problèmes de « taille »
équivalente, ce qui garantit une bonne répartition des tâches entre ouvriers.</li>
</ul>

<h5>Classes et méthodes utiles</h5>

<ul>
<li>la classe <code>java.util.concurrent.Executors</code>, permet de créer des pools de threads par 
appel de <code>newFixedThreadPool()</code> ou <code>newCachedThreadPool()</code> (cf supra)</li>
<li>la classe <code>ExecutorService</code> et sa superclasse <code>Executor</code>, définissent l'interface 
d'un exécuteur, avec notamment les méthodes <code>submit()</code>, <code>execute()</code> (cf supra) et 
<code>shutdown()</code> (gestion de la terminaison de l'exécuteur)</li>
<li>la classe <code>Future</code> fournit (immédiatement) une référence vers le résultat (à venir)
d'une tâche <code>Callable</code>soumise à l'exécuteur par <code>submit()</code>. L'appel de la méthode <code>get()</code>
permet d'obtenir le résultat effectif, en attendant s'il n'est pas encore disponible.</li>
<li>les tâches ne renvoyant pas de résultat sont des <code>Runnable</code>, soumises à l'exécuteur par
<code>execute()</code>.</li>
</ul>

<h5>Un exemple</h5>

<pre><code>import java.util.concurrent.Future;
import java.util.concurrent.Callable;
import java.util.concurrent.Executors;
import java.util.concurrent.ExecutorService;

class SigmaC implements Callable&lt;Long&gt; {
    private long début;
    private long fin;

    SigmaC(long d, long f) { début = d; fin = f;}

    @Override
    public  Long call() { // le résultat doit être un objet
        long s = 0;
        for (long i = début; i &lt;= fin; i++) s = s + i;
        return s;
    }                
}

class SigmaR implements Runnable {
    private long début;
    private long fin;

    SigmaR(long d, long f) { début = d; fin = f;}

    @Override
    public  void run() {
        long s = 0;
        for (long i = début; i &lt;= fin; i++) s = s + i;
        System.out.println("Calcul terminé. ∑("+début+","+fin+") = "+s);
    }                
}

public class Somme {     
    public static void main(String[] args) throws Exception {

        ExecutorService poule = Executors.newFixedThreadPool(2);

        Future&lt;Long&gt; f1 = poule.submit(new SigmaC(0L,1_000_000_000L));
        Future&lt;Long&gt; f2 = poule.submit(new SigmaC(0L,4_000_000_000L));
        poule.execute(new SigmaR(900_000L,1_000_000_000L));
        Future&lt;Long&gt; f3 = poule.submit(new SigmaC(1,100));
        Future&lt;Long&gt; f4 = poule.submit(new SigmaC(0L,3_000_000_000L));

        poule.shutdown();

        System.out.println("Résultat obtenu. f1 = "+f1.get());
        System.out.println("Résultat obtenu. f2 = "+f2.get());        
        System.out.println("Résultat obtenu. f3 = "+f3.get());        
        System.out.println("Résultat obtenu. f4 = "+f4.get());
    }    
}
</code></pre>

<h5>Commentaires</h5>

<ul>
<li>L'application crée un pool de taille fixe (2), et lance 5 tâches : les deux premières
et les deux dernières soumises (<code>Callable</code> , soumises par appel à <code>submit()</code>) 
rendent un résultat <code>Future</code>, récupéré de manière synchrone (bloquante) par l'appel à la 
méthode <code>get()</code>. La troisième (<code>Runnable</code>, soumise par appel à <code>execute()</code>) s'exécute de 
manière asynchrone.</li>
<li>L'exécution voit la tâche <code>Runnable</code> terminer après la première soumise (<code>f1</code>), car bien que plus courte, elle ne peut démarrer tant que l'une des deux premières tâches lancées
n'est pas terminée, la taille du pool étant de 2. L'appel <code>f2.get()</code> entraîne l'attente de 
la terminaison de <code>f2</code>, plus longue que <code>f1</code>et la tâche <code>Runnable</code> cumulées. L'appel de 
<code>f3.get()</code> retourne immédiatement, car <code>f3</code>, courte est déjà terminé. L'appel <code>f4.get()</code> entraîne l'attente de la terminaison de <code>f4</code>. </li>
<li><code>shutdown</code> permet de terminer proprement l'exécuteur, qui dès lors n'accepte plus de nouvelles tâches. L'application Java termine avec la dernière tâche traitée. Si <code>shutdown</code> 
est omis, l'application ne peut terminer, car les threads de l'exécuteur restent en attente de nouvelles tâches.</li>
<li>L'archive contient une variante (<code>SommePlus</code>) de l'application <code>Somme</code>, qui illustre
l'utilisation de :
<ul>
<li><code>invokeAll()</code> sur une collection de tâches/actions pour soumettre une collection 
(ici une liste) de <code>Callable</code>. Les résultats sont alors rendus dans une liste de <code>Future</code>;</li>
<li><code>get()</code> sur les <code>Future</code> de cette liste, pour récupérer les résultats effectifs</li>
</ul></li>
</ul>

<h3>Pool Fork/Join (Schéma Map/Reduce)</h3>

<p>La classe <code>ForkJoinPool</code> est un exécuteur dont l'ordonnancement est adapté à une 
parallélisation selon le schéma <em>fork/join</em> (voir cours, planches 28-30). 
Le principe (récursif) est</p>

<ul>
<li>de traiter directement (séquentiellement) un problème si sa taille est suffisamment petite</li>
<li>sinon, de diviser le problème en sous-problèmes, qui seront traités en parallèle (<code>fork</code>)
et dont les résultats seront attendus (<code>join</code>) et agrégés.</li>
</ul>

<p>Ce schéma de programmation permet de créer dynamiquement un nombre de tâches adapté à la
taille de chacun des (sous)-problèmes rencontrés, chacune des tâches créées représentant
une charge de travail équivalente. Ce schéma est donc bien adapté au traitement de problèmes
irréguliers, de grande taille. L'ordonnanceur de la classe <code>ForkJoinPool</code> comporte en outre
une régulation (vol de tâches) qui permet l'adaptation de l'exécution aux capacités de calcul
disponibles.</p>

<p>Il est important de noter que ce schéma repose sur le fait que les sous-tâches créées 
s'exécutent en parallèle, et donc sur l'hypothèse qu'elles sont complètement indépendantes.
Tout conflit d'accès aux ressources, ou synchronisation compromet l'efficacité de ce schéma.
<strong>Le schéma Fork/Join est donc idéalement et principalement destiné aux calculs 
intensifs, irréguliers, en mémoire pure (sans E/S), sans variables partagées en cours 
d'exécution</strong> : les interactions et synchronisations entre tâches sont alors limitées 
aux interactions entre une tâche mère et ses tâches filles, lorsque celles-ci ont terminé,
 et que la tâche mêre récupère les résultats des tâches filles pour les agréger.</p>

<h5>Classes et méthodes utiles</h5>

<ul>
<li><code>ForkJoinPool</code>: classe définissant l'exécuteur. Une instance de <code>ForkJoinPool</code> doit être
créée une fois et une seule pour toute la durée de  l'application (ce n'est pas 
obligatoire, mais c'est vivement conseillé, même pour les experts).</li>
<li><code>RecursiveTask&lt;V&gt;</code> : définit une tâche soumise à l'exécuteur, fournissant un résultat</li>
<li><code>RecursiveAction</code> : définit une tâche soumise à l'exécuteur, ne fournissant pas de résultat</li>
<li><code>ForkJoinTask&lt;V&gt;</code> : superclasse de RecursiveTask<V> and RecursiveAction, définissant la
plupart des méthodes utiles, comme <code>fork()</code> et <code>join()</code>.</li>
</ul>

<h5>Un exemple</h5>

<p>(fourni également dans l'archive jointe) réalise le schéma fork/join et illustre
 l'utilisation des principales classes et méthodes dans ce cadre. Dans cette application,
 les données à traiter sont représentées par un simple entier, qui symbolise leur volume.</p>

<pre><code>import java.util.concurrent.RecursiveTask;
import java.util.concurrent.ForkJoinPool;

class TraiterProblème extends RecursiveTask&lt;Integer&gt; {

 private int resteAFaire = 0;
 private int résultat = 0;
 static final int SEUIL = 10;

 TraiterProblème(int resteAFaire) {
    this.resteAFaire = resteAFaire;
}

 protected Integer compute() {

    //si la tâche est trop grosse, on la décompose en 2
    if(this.resteAFaire &gt; SEUIL) {
        System.out.println("Décomposition de resteAFaire : " + this.resteAFaire);

        TraiterProblème sp1 = new TraiterProblème(this.resteAFaire / 2);
        TraiterProblème sp2 = new TraiterProblème(this.resteAFaire / 2);

        sp1.fork();
        sp2.fork();

        résultat = sp1.join()+ sp2.join();

        return résultat;

    } else {
        System.out.println("Traitement direct de resteAFaire : " + this.resteAFaire);
        return resteAFaire * 3;
    }
 }
}

public class FJG {
 static ForkJoinPool fjp = new ForkJoinPool();
 static final int TAILLE = 1024; //Attention : nécessairement une puissance de 2

 public static void main(String[] args) throws Exception {
    TraiterProblème monProblème = new TraiterProblème(TAILLE);
    int résultat = fjp.invoke(monProblème);
    System.out.println("Résultat final = " + résultat);
 }
}
</code></pre>

<h5>Commentaires</h5>

<ul>
<li>la méthode abstraite <code>compute()</code> définie dans <code>RecursiveTask</code> et <code>RecursiveAction</code>
contient le code du calcul récursif proprement dit. C'est l'analogue de la méthode <code>run()</code> 
pour la classe <code>Runnnable</code> ou de la méthode <code>call()</code> pour la classe <code>Callable</code>.</li>
<li><code>SEUIL</code> est la taille de problème à partir duquel le travail n'est plus subdivisé. Ainsi
qu'indiqué précédemment sa valeur est un compromis, dépendant de la nature du problème. Une
règle empirique est que le nombre de sous-tâches créés devrait être compris entre 100 et
10 000. Il faut aussi savoir que le pool ne peut comporter plus de 32K ouvriers.</li>
<li>le <code>ForkJoinPool</code> doit être créé une fois et une seule pour toute la durée de 
l'application (ce n'est pas obligatoire, mais c'est déconseillé, même pour les experts).
La méthode employée ici pour créer ce pool est celle nécessaire en Java 6 et 7.
A partir de Java 8, cette création est inutile, car la classe <code>ForkJoinPool</code> dispose d'un
d'un pool par défaut (attribut de classe), dont la référence peut être obtenue par appel
de la méthode de classe <code>ForkJoinPool.commonPool()</code>.  L'archive contient 
une variante (<code>FJGPlus</code>) de l'application <code>FJG</code>, qui utilise cette facilité.</li>
<li>l'appel <code>fjp.invoke(monProblème);</code> permet de soumettre la tâche racine au pool.</li>
</ul>

<h5>Quelques écueils</h5>

<ul>
<li><p>l'implémentation actuelle de <code>ForkJoinPool</code> est d'autant moins efficace que les tâches
sont nombreuses. Ainsi, l'implémentation suivante de la branche <code>if</code> de la méthode <code>compute</code>
précédente aurait été sensiblement plus efficace (mais moins naturelle) :
    if(this.resteAFaire > SEUIL) {
        System.out.println("Décomposition de resteAFaire : " + this.resteAFaire);</p>

<pre><code>    TraiterProblème sp1 = new TraiterProblème(this.resteAFaire / 2);
    TraiterProblème sp2 = new TraiterProblème(this.resteAFaire / 2);
    sp1.fork();
    résultat = sp2.compute();
    résultat = sp1.join()+résultat
    return résultat;
}
</code></pre></li>
<li>il ne faut pas oublier que <code>join()</code> est bloquant. Ainsi l'échange des appels à <code>join()</code> et
<code>compute()</code> dans la variante précédente aurait pour effet d'aboutir à un programme séquentiel...</li>
</ul>

<h2>Exercices</h2>

<ul>
<li>Paralléliser une agrégation (maximum d'un tableau)
<ul>
<li>avec un ForkJoinPool</li>
<li>avec un pool</li>
<li>comparer ces deux versions avec la version séquentielle</li>
</ul></li>
<li>Paralléliser TriFusion (pour illustrer map-reduce, même si le pb est régulier)
<ul>
<li>avec un ForkJoinPool</li>
<li>avec un pool</li>
<li>comparer ces deux versions avec la version séquentielle</li>
</ul></li>
<li>Comptage de mots dans un répertoire (problème irrégulier)
<ul>
<li>avec un ForkJoinPool</li>
<li>avec un pool</li>
<li>comparer ces deux versions avec la version séquentielle</li>
</ul></li>
<li>Pour aller plus loin, 
<ul>
<li>paralléliser huit reines, sudoku</li>
<li>serveur http, pour illustrer l'écroulement</li>
</ul></li>
</ul>

<h3>Rappel</h3>

<p>Selon votre configuration, il est possible que le format par défaut pour les fichiers 
 sources Java soit le format ASCII. Dans ce cas, des erreurs apparaitront lors de la
  compilation des fichiers de l'archive, qui sont codés en UTF8.</p>

<p>Pour remédier à cela, il est possible de positionner la variable d'environnement
JAVA_TOOL_OPTIONS (en bash : <code>export JAVA_TOOL_OPTIONS=-Dfile.encoding=UTF8</code>), </p>

<p>ou encore de lancer la compilation avec l'option <code>-encoding UTF8</code>, ce qui donne ici :</p>

<pre><code>    javac -encoding UTF8 *.java
</code></pre>

<h2>Tester les performances d'applications concurrentes en Java : quelques remarques pratiques</h2>

<ul>
<li>sources de perturbation : cache, compilateur à la volée, ramasse miettes et optimiseur, 
charge de l'environnement (matériel, réseau)
-> répéter les mesures et retenir la meilleure</li>
<li>tester sur des volumes de données significatifs</li>
<li>connaître le nombre de processeurs réels disponibles</li>
<li>éviter les optimisations sauvages
<ul>
<li>avoir des tâches suffisamment complexes  </li>
<li>avoir un jeu de données varié (non constant en valeur et dans le temps)</li>
</ul></li>
<li>arrêter la décomposition en sous tâches à un seuil raisonnable</li>
</ul>
